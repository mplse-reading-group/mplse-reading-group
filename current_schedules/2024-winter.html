<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="../css/schedule.css" />
    </head>
    <body>
        <main role="main">
            <h1>2024-winter</h1>
                <table style="width:100%;">
        <colgroup>
            <col style="width: 1%">
            <col style="width: 2%">
            <col style="width: 95%">
        </colgroup>
        <thead>
            <tr class="header">
                <th>Speaker</th>
                <th>Time ∧ Location</th>
                <th>Paper</th>
            </tr>
            <tr class="odd">
                <th></th>
                <th colspan="2">Abstract</th>
            </tr>
        </thead>
        <tbody>

        <tr class="odd">
            <td>Eric Bond</td>
            <td>March 8th, 4-5pm in 3901 BBB</td>
            <td><a href="https://dl.acm.org/doi/10.1145/2535838.2535852">Polynomial Time and Dependent Types</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">I will be presenting Bob Atkey's 2024 POPL paper: Abstract: We combine dependent types with linear type systems that soundly and completely capture polynomial time computation.  We explore two systems for capturing polynomial time:  one system that disallows construction of iterable data,  and one, based on the LFPL system of Martin Hofmann, that controls construction via a payment method.  Both of these are extended to full dependent types via Quantitative Type Theory, allowing for arbitrary computation in types alongside guaranteed polynomial time computation in terms.  We prove the soundness of the systems using a realisability technique due to Dal Lago and Hofmann. Our long-term goal is to combine the extensional reasoning of type theory with intensional reasoning about the resources intrinsically consumed by programs.  This paper is a step along this path, which we hope will lead both to practical systems for reasoning about programs’ resource usage, and to theoretical use as a form of synthetic computational complexity theory.<br></td>
        </tr>

        <tr class="odd">
            <td>Johnson He</td>
            <td>March 15th?, 4-5pm@3901BBB</td>
            <td><a href="Link TBD">TBD, something about semantics</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">Any requests?<br></td>
        </tr>

        <tr class="odd">
            <td>Yuchen Jiang</td>
            <td>March 22th?, 4-5pm@3901BBB</td>
            <td><a href="https://dl.acm.org/doi/10.1145/322169.322183">(TBD) Continuation-Based Program Transformation Strategies</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">(TBD) I'll present Mitchell Wand's (classic) work on CPS transformation. The topic is mature and well-known, so I'll try my best to make it more entertaining. Abstract: Program transformations often involve the generalization of a function to take additional arguments. It is shown that in many cases such an additional variable arises as a representation of the continuation or global context in which the function is evaluated. By considering continuations, local transformation strategies can take advantage of global knowledge. The general results are followed by two examples: the ɑ-β tree pruning algorithm and an algorithm for the conversion of a propositional formula to conjunctive normal form.<br></td>
        </tr>

        <tr class="odd">
            <td>TODO</td>
            <td>TODO</td>
            <td><a href="TODO">TODO</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">TODO<br></td>
        </tr>

        </tbody>
    </table>


        </main>
    </body>
</html>
