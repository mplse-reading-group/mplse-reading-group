<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>MPLSE Reading Group - Schedule</title>
        <link rel="stylesheet" href="/css/default.css" />
    </head>
    <body>
        <header>
            <div class="logo">
                <a href="/">MPLSE Reading Group</a>
            </div>
            <nav>
                <a href="/">Home</a>
                <a href="/about.html">About</a>
                <a href="/past.html">Past</a>
                <!--
                <a href="/archive.html">Archive</a>
                -->
            </nav>
        </header>

        <main role="main">
            <h1>Schedule</h1>
            <p>
</p>
<!--
<img src="/images/haskell-logo.png" style="float: right; margin: 10px;" />
-->

<hr>
<a href="https://umich.zoom.us/j/93467587435">Zoom link</a>
<br>
Passcode: LAMBDA
<hr>

<div>
    
        <p>
            <!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="../css/schedule.css" />
    </head>
    <body>
        <main role="main">
            <h1>2024-fall</h1>
                <table style="width:100%;">
        <colgroup>
            <col style="width: 1%">
            <col style="width: 2%">
            <col style="width: 95%">
        </colgroup>
        <thead>
            <tr class="header">
                <th>Speaker</th>
                <th>Time âˆ§ Location</th>
                <th>Paper</th>
            </tr>
            <tr class="odd">
                <th></th>
                <th colspan="2">Abstract</th>
            </tr>
        </thead>
        <tbody>

        <tr class="odd">
            <td>Johnson He</td>
            <td>September 27th, 4:30-5pm@3901 BBB</td>
            <td><a href="https://dl.acm.org/doi/10.1145/3674642">Oxidizing OCaml with Modal Memory Management</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">Programmers can often improve the performance of their programs by reducing heap allocations: either by allocating on the stack or reusing existing memory in-place. However, without safety guarantees, these optimizations can easily lead to use-after-free errors and even type unsoundness. In this paper, we present a design based on modes which allows programmers to safely reduce allocations by using stack allocation and in-place updates of immutable structures. We focus on three mode axes: affinity, uniqueness and locality. Modes are fully backwards compatible with existing OCaml code and can be completely inferred. Our work makes manual memory management in OCaml safe and convenient and charts a path towards bringing the benefits of Rust to OCaml.<br></td>
        </tr>

        <tr class="odd">
            <td>Andrew Blinn</td>
            <td>October 18th, 4-5pm@3901 BBB</td>
            <td><a href="https://arxiv.org/abs/2409.00921">Statically Contextualizing Large Language Models with Typed Holes</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">Large language models (LLMs) have reshaped the landscape of program synthesis. However, contemporary LLM-based code completion systems often hallucinate broken code because they lack appropriate context, particularly when working with definitions not in the training data nor near the cursor. This paper demonstrates that tight integration with the type and binding structure of a language, as exposed by its language server, can address this contextualization problem in a token-efficient manner. In short, we contend that AIs need IDEs, too! In particular, we integrate LLM code generation into the Hazel live program sketching environment. The Hazel Language Server identifies the type and typing context of the hole being filled, even in the presence of errors, ensuring that a meaningful program sketch is always available. This allows prompting with codebase-wide contextual information not lexically local to the cursor, nor necessarily in the same file, but that is likely to be semantically local to the developer's goal. Completions synthesized by the LLM are then iteratively refined via further dialog with the language server. To evaluate these techniques, we introduce MVUBench, a dataset of model-view-update (MVU) web applications. These applications serve as challenge problems due to their reliance on application-specific data structures. We find that contextualization with type definitions is particularly impactful. After introducing our ideas in the context of Hazel we duplicate our techniques and port MVUBench to TypeScript in order to validate the applicability of these methods to higher-resource languages. Finally, we outline ChatLSP, a conservative extension to the Language Server Protocol (LSP) that language servers can implement to expose capabilities that AI code completion systems of various designs can use to incorporate static context when generating prompts for an LLM.<br></td>
        </tr>

        </tbody>
    </table>


        </main>
    </body>
</html>

        </p>
    
</div>

        </main>

        <footer>
            <ul style="margin: 0; list-style: none">
                <li>
                    <a href="https://github.com/mplse-reading-group/mplse-reading-group.github.io">Site Source</a>
                </li>
                <li>
                    Site proudly generated by
                    <a href="http://jaspervdj.be/hakyll">Hakyll</a>
                </li>
            </ul>
        </footer>
    </body>
</html>
