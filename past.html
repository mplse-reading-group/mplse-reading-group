<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>MPLSE Reading Group - Past</title>
        <link rel="stylesheet" href="/css/default.css" />
    </head>
    <body>
        <header>
            <div class="logo">
                <a href="/">MPLSE Reading Group</a>
            </div>
            <nav>
                <a href="/">Home</a>
                <a href="/about.html">About</a>
                <a href="/past.html">Past</a>
                <!--
                <a href="/archive.html">Archive</a>
                -->
            </nav>
        </header>

        <main role="main">
            <h1>Past</h1>
            <div>
    
        <p>
            <!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="../css/schedule.css" />
    </head>
    <body>
        <main role="main">
            <h1>2024-spring-summer</h1>
                <table style="width:100%;">
        <colgroup>
            <col style="width: 1%">
            <col style="width: 2%">
            <col style="width: 95%">
        </colgroup>
        <thead>
            <tr class="header">
                <th>Speaker</th>
                <th>Time ∧ Location</th>
                <th>Paper</th>
            </tr>
            <tr class="odd">
                <th></th>
                <th colspan="2">Abstract</th>
            </tr>
        </thead>
        <tbody>

        <tr class="odd">
            <td>Wenxuan Guo</td>
            <td>March 10th, 4-5pm@zoom</td>
            <td><a href="no links">ProofBlocks</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">1. Autogradeable Scaffolding Activities for Learning to Write Proofs<br><br>Authors: Seth Poulsen, Mahesh Viswanathan, Geoffrey L. Herman, and Matthew West <br><br>Abstract: This paper presents "Proof Blocks," a novel software tool<br>  designed to assist in the education of mathematical proofs by providing a<br>  platform where students can engage with proofs through a drag-and-drop<br>  interface. This tool automates grading and offers immediate feedback,<br>  making it particularly valuable in large classes.<br><br><br>2. Efficiency of Learning from Proof Blocks Versus Writing Proofs<br><br>Authors: Seth Poulsen, Yael Gertner, Benjamin Cosman, Matthew West, and Geoffrey L. Herman<br><br>Abstract: This study evaluates the effectiveness of<br>  Proof Blocks compared to traditional proof-writing exercises. It focuses<br>  on the efficiency and learning gains associated with each method through<br>  a controlled study involving students from a discrete mathematics course.<br><br><br>3. Autogenerating Natural Language Proofs for Proof Education<br><br>Authors: Seth Poulsen, Matthew West, and Talia Ringer<br><br>Abstract: This research introduces a Coq plugin that generates natural language proofs from formal proofs, aiming to make proof education more accessible and understandable to students, especially beginners.<br><br>4. Evaluation of Educational Software Tools in Teaching Proofs<br><br>Authors: Seth Poulsen, Geoffrey L. Herman, Mahesh Viswanathan, Matthew West<br><br>Abstract: This paper examines the use of Proof Blocks in exams for a discrete mathematics course, analyzing thousands of student responses. The data indicates that Proof Blocks are easier for students compared to traditional written proofs, yet yield similar insights into student understanding. Surveys also suggest that students find the interface user-friendly and effective in assessing their proof-writing skills.<br></td>
        </tr>

        </tbody>
    </table>


        </main>
    </body>
</html>

        </p>
    
        <p>
            <!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="../css/schedule.css" />
    </head>
    <body>
        <main role="main">
            <h1>2024-winter</h1>
                <table style="width:100%;">
        <colgroup>
            <col style="width: 1%">
            <col style="width: 2%">
            <col style="width: 95%">
        </colgroup>
        <thead>
            <tr class="header">
                <th>Speaker</th>
                <th>Time ∧ Location</th>
                <th>Paper</th>
            </tr>
            <tr class="odd">
                <th></th>
                <th colspan="2">Abstract</th>
            </tr>
        </thead>
        <tbody>

        <tr class="odd">
            <td>Eric Bond</td>
            <td>March 8th, 4-5pm in 3901 BBB</td>
            <td><a href="https://dl.acm.org/doi/10.1145/2535838.2535852">Polynomial Time and Dependent Types</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">I will be presenting Bob Atkey's 2024 POPL paper: Abstract: We combine dependent types with linear type systems that soundly and completely capture polynomial time computation.  We explore two systems for capturing polynomial time:  one system that disallows construction of iterable data,  and one, based on the LFPL system of Martin Hofmann, that controls construction via a payment method.  Both of these are extended to full dependent types via Quantitative Type Theory, allowing for arbitrary computation in types alongside guaranteed polynomial time computation in terms.  We prove the soundness of the systems using a realisability technique due to Dal Lago and Hofmann. Our long-term goal is to combine the extensional reasoning of type theory with intensional reasoning about the resources intrinsically consumed by programs.  This paper is a step along this path, which we hope will lead both to practical systems for reasoning about programs’ resource usage, and to theoretical use as a form of synthetic computational complexity theory.<br></td>
        </tr>

        <tr class="odd">
            <td>Johnson He</td>
            <td>March 15th, 4-5pm@3901BBB</td>
            <td><a href="https://ebookcentral-proquest-com.proxy.lib.umich.edu/lib/umichigan/reader.action?docID=684605&ppg=92">The groupoid interpretation of type theory (1998)</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">This is the extended and slightly more modern version of the historic paper,   "The Groupoid Model Refutes Uniqueness of Identity Proofs (1994)", using Categories with Families (CwFs) instead of Categories with Attributes (CwAs).<br>I hope we'll see a more modern notion of model in the reading group soon.<br></td>
        </tr>

        <tr class="odd">
            <td>Yuchen Jiang</td>
            <td>March 29th, 4-5pm@3901BBB</td>
            <td><a href="https://dl.acm.org/doi/10.1145/322169.322183">Continuation-Based Program Transformation Strategies</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">I'll present Mitchell Wand's (classic) work on CPS transformation. The topic is mature and well-known, so I'll try my best to make it more entertaining.<br><br>Abstract:<br>Program transformations often involve the generalization of a function to take additional arguments. It is shown that in many cases such an additional variable arises as a representation of the continuation or global context in which the function is evaluated. By considering continuations, local transformation strategies can take advantage of global knowledge. The general results are followed by two examples: the ɑ-β tree pruning algorithm and an algorithm for the conversion of a propositional formula to conjunctive normal form.<br></td>
        </tr>

        <tr class="odd">
            <td>Matthew Keenan</td>
            <td>April 5th, 4-5pm@3901 BBB</td>
            <td><a href="http://liamoc.net/holbert/">Holbert: Reading, Writing and Proving in the Browser</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">Abstract:<br>This paper presents Holbert a work-in-progress pedagogical proof assistant and online textbook platform, aimed at the educational use-case, specifically for the teaching of programming language theory. Holbert allows proof exercises and rule definitions to be embedded directly in an online textbook, where proofs and rules can be manipulated using a graphical interface. We give an overview of the logical foundations of Holbert, examples of its use, and give an update as to its current implementation status.<br></td>
        </tr>

        <tr class="odd">
            <td>June Kim</td>
            <td>April 12th, 4-5pm@3901 BBB</td>
            <td><a href="https://dspace.mit.edu/bitstream/handle/1721.1/137905.2/SyGuS_JournalVersion.pdf">Syntax-Guided Synthesis</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">The classical formulation of the program-synthesis problem is to find a program that meets a correctness specification given as a logical formula. Recent work on program synthesis and program optimization illustrates many potential benefits of allowing the user to supplement the logical specification with a syntactic template that constrains the space of allowed implementations. Our goal is to identify the core computational problem common to these proposals in a logical framework. The input to the syntax-guided synthesis problem (SyGuS) consists of a background theory, a semantic correctness specification for the desired program given by a logical formula, and a syntactic set of candidate implementations given by a grammar. The computational problem then is to find an implementation from the set of candidate expressions so that it satisfies the specification in the given theory. We describe alternative solution strategies that combine learning, counterexample analysis and constraint solving. We report on prototype implementations, and present experimental results on the set of benchmarks collected as part of the first SyGuS-Comp competition held in July 2014.<br></td>
        </tr>

        <tr class="odd">
            <td>Steven Schaefer</td>
            <td>April 19th, 4-5pm@3901 BBB</td>
            <td><a href="https://www2.mathematik.tu-darmstadt.de/~streicher/sstt.pdf">A Model of Type Theory in Simplicial Sets</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">In the same vein as Johnson's presentation of how the groupoid model refutes UIP, I'd like to continue going through a historical treament of homotopy type theory (HoTT). Streicher's paper presents simplicial sets --- a notion of spaces --- as a model of type theory. We will investigate this model and role that Voevodsky's univalence axiom plays in it.<br></td>
        </tr>

        </tbody>
    </table>


        </main>
    </body>
</html>

        </p>
    
        <p>
            <!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="../css/schedule.css" />
    </head>
    <body>
        <main role="main">
            <h1>2024-fall</h1>
                <table style="width:100%;">
        <colgroup>
            <col style="width: 1%">
            <col style="width: 2%">
            <col style="width: 95%">
        </colgroup>
        <thead>
            <tr class="header">
                <th>Speaker</th>
                <th>Time ∧ Location</th>
                <th>Paper</th>
            </tr>
            <tr class="odd">
                <th></th>
                <th colspan="2">Abstract</th>
            </tr>
        </thead>
        <tbody>

        <tr class="odd">
            <td>Johnson He</td>
            <td>September 27th, 4:30-5pm@3901 BBB</td>
            <td><a href="https://dl.acm.org/doi/10.1145/3674642">Oxidizing OCaml with Modal Memory Management</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">Programmers can often improve the performance of their programs by reducing heap allocations: either by allocating on the stack or reusing existing memory in-place. However, without safety guarantees, these optimizations can easily lead to use-after-free errors and even type unsoundness. In this paper, we present a design based on modes which allows programmers to safely reduce allocations by using stack allocation and in-place updates of immutable structures. We focus on three mode axes: affinity, uniqueness and locality. Modes are fully backwards compatible with existing OCaml code and can be completely inferred. Our work makes manual memory management in OCaml safe and convenient and charts a path towards bringing the benefits of Rust to OCaml.<br></td>
        </tr>

        <tr class="odd">
            <td>Andrew Blinn</td>
            <td>October 18th, 4-5pm@3901 BBB</td>
            <td><a href="https://arxiv.org/abs/2409.00921">Statically Contextualizing Large Language Models with Typed Holes</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">Large language models (LLMs) have reshaped the landscape of program synthesis. However, contemporary LLM-based code completion systems often hallucinate broken code because they lack appropriate context, particularly when working with definitions not in the training data nor near the cursor. This paper demonstrates that tight integration with the type and binding structure of a language, as exposed by its language server, can address this contextualization problem in a token-efficient manner. In short, we contend that AIs need IDEs, too! In particular, we integrate LLM code generation into the Hazel live program sketching environment. The Hazel Language Server identifies the type and typing context of the hole being filled, even in the presence of errors, ensuring that a meaningful program sketch is always available. This allows prompting with codebase-wide contextual information not lexically local to the cursor, nor necessarily in the same file, but that is likely to be semantically local to the developer's goal. Completions synthesized by the LLM are then iteratively refined via further dialog with the language server. To evaluate these techniques, we introduce MVUBench, a dataset of model-view-update (MVU) web applications. These applications serve as challenge problems due to their reliance on application-specific data structures. We find that contextualization with type definitions is particularly impactful. After introducing our ideas in the context of Hazel we duplicate our techniques and port MVUBench to TypeScript in order to validate the applicability of these methods to higher-resource languages. Finally, we outline ChatLSP, a conservative extension to the Language Server Protocol (LSP) that language servers can implement to expose capabilities that AI code completion systems of various designs can use to incorporate static context when generating prompts for an LLM.<br></td>
        </tr>

        <tr class="odd">
            <td>Alexander Bandukwala</td>
            <td>November 15th, 4-5pm@3901 BBB</td>
            <td><a href="https://www.cs.cmu.edu/~aldrich/papers/objects-essay.pdf">The Power of Interoperability: Why Objects Are Inevitable</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">Three years ago in this venue, Cook argued that in their essence, objects are what Reynolds called procedural data structures. His observation raises a natural question: if procedural data structures are the essence of objects, has this contributed to the empirical success of objects, and if so, how?<br>This essay attempts to answer that question. After reviewing Cook’s definition, I propose the term service abstractions to capture the essential nature of objects. This terminology emphasizes, following Kay, that objects are not primarily about representing and manipulating data, but are more about providing services in support of higher-level goals. Using examples taken from object-oriented frameworks, I illustrate the unique design leverage that service abstractions provide: the ability to define abstractions that can be ex- tended, and whose extensions are interoperable in a first-class way. The essay argues that the form of inter- operable extension supported by service abstractions is essential to modern software: many modern frame- works and ecosystems could not have been built with- out service abstractions. In this sense, the success of objects was not a coincidence: it was an inevitable con- sequence of their service abstraction nature.<br></td>
        </tr>

        </tbody>
    </table>


        </main>
    </body>
</html>

        </p>
    
        <p>
            <!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="../css/schedule.css" />
    </head>
    <body>
        <main role="main">
            <h1>2023-fall</h1>
                <table style="width:100%;">
        <colgroup>
            <col style="width: 1%">
            <col style="width: 2%">
            <col style="width: 95%">
        </colgroup>
        <thead>
            <tr class="header">
                <th>Speaker</th>
                <th>Time ∧ Location</th>
                <th>Paper</th>
            </tr>
            <tr class="odd">
                <th></th>
                <th colspan="2">Abstract</th>
            </tr>
        </thead>
        <tbody>

        <tr class="odd">
            <td>Yash Gaitonde</td>
            <td>10/13 4-5pm@3941 BBB</td>
            <td><a href="https://advait.org/publications-web/sarkar-2022-lambdas/">End-user encounters with lambda abstraction in spreadsheets</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">The value of computational abstractions to non-expert end-user programmers is contentious. We study reactions to the lambda function in Microsoft Excel, which enables users to define their own functions using the spreadsheet formula language, through a thematic analysis of nearly 2,700 comments posted on the Reddit, Hacker News, YouTube, and Microsoft Tech Community online forums. We find that computational abstractions are viewed both as helpful and harmful, that users encounter learning and understanding barriers to applying them, and that there are deficiencies and opportunities in tooling such as in formula editing, versioning, reuse and sharing. We find that the introduction of lambda prompts new debate around whether spreadsheets are code, whether writing formulas can be considered programming, and whether spreadsheet users identify themselves as programmers.<br></td>
        </tr>

        <tr class="odd">
            <td>Johnson He</td>
            <td>10/27 4-5pm@3941 BBB</td>
            <td><a href="https://prl.khoury.northeastern.edu/blog/static/scott-69-93-type-theoretical-alternative.pdf">A type-theoretical alternative to ISWIM, CUCH, OWHY</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">Abstract from the paper:<br><br>The paper (first written in 1969 and circulated privately) concerns the definition, axiomatization, and applications of the hereditarily monotone and continuous functionals generated from the integers and the Booleans (plus “undefined” elements). The system is formulated as a typed system of combinators (or as a typed λ-calculus) with a recursion operator (the least fixed-point operator), and its proof rules are contrasted to a certain extent with those of the untyped λ-calculus. For publication (1993), a new preface has been added, and many bibliographical references and comments in footnotes have been appended.<br></td>
        </tr>

        <tr class="odd">
            <td>Steven Shaefer</td>
            <td>11/03 4-5pm@3941 BBB</td>
            <td><a href="https://plv.mpi-sws.org/rustbelt/popl18/paper.pdf">RustBelt: Securing the Foundations of the Rust Programming Language</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">TLDR; Some of the first verification of Rust's borrowing semantics. A little outdated now, but instructive.<br><br>Rust is a new systems programming language that promises to overcome the seemingly fundamental tradeoff between high-level safety guarantees and low-level control over resource management. Unfortunately, none of Rust’s safety claims have been formally proven, and there is good reason to question whether they actually hold. Specifically, Rust employs a strong, ownership-based type system, but then extends the expressive power of this core type system through libraries that internally use unsafe features. In this paper, we give the first formal (and machine-checked) safety proof for a language representing a realistic subset of Rust. Our proof is extensible in the sense that, for each new Rust library that uses unsafe features, we can say what verification condition it must satisfy in order for it to be deemed a safe extension to the language. We have carried out this verification for some of the most important libraries that are used throughout the Rust ecosystem.<br></td>
        </tr>

        <tr class="odd">
            <td>Andrew Blinn</td>
            <td>11/10 4-5pm@3941 BBB</td>
            <td><a href="https://users.cs.utah.edu/plt/publications/oopsla23-faadffggkkmppst.pdf">Rhombus: A New Spin on Macros without All the Parentheses</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">Rhombus is a new language that is built on Racket. It offers the same kind of language extensibility as Racket itself, but using conventional (infix) notation. Although Rhombus is far from the first language to support Lisp-style macros without Lisp-style parentheses, Rhombus offers a novel synthesis of macro technology that is practical and expressive. A key element is the use of multiple binding spaces for context-specific sublanguages.  For example, expressions and pattern-matching forms can use the same operators with different meanings and without creating conflicts. Context-sensitive bindings, in turn, facilitate a language design that reduces the notational distance between the core language and macro facilities. For example, repetitions can be defined and used in binding and expression contexts generally, which enables a smoother transition from programming to metaprogramming. Finally, since handling static information (such as types) is also a necessary part of growing macros beyond Lisp, Rhombus includes support in its expansion protocol for communicating static information among bindings and expressions. The Rhombus implementation demonstrates that all of these pieces can work together in a coherent and user-friendly language.<br></td>
        </tr>

        <tr class="odd">
            <td>Matthew Keenan ∧ Elanor Tang</td>
            <td>11/17 4-5pm@3941 BBB</td>
            <td><a href="https://dl.acm.org/doi/pdf/10.1145/2980983.2908093">Program Synthesis from Polymorphic Refinement Types</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2">We present a method for synthesizing recursive functions that provably satisfy a given specification in the form of a polymorphic refinement type. We observe that such specifications are particularly suitable for program synthesis for two reasons. First, they offer a unique combination of expressive power and decidability, which enables automatic verification—and hence synthesis—of nontrivial programs. Second, a type-based specification for a program can often be effectively decomposed into independent specifications for its components, causing the synthesizer to consider fewer component combinations and leading to a combinatorial reduction in the size of the search space. At the core of our synthesis procedure is a new algorithm for refinement type checking, which supports specification decomposition. We have evaluated our prototype implementation on a large set of synthesis problems and found that it exceeds the state of the art in terms of both scalability and usability. The tool was able to synthesize more complex programs than those reported in prior work (several sorting algorithms and operations on balanced search trees), as well as most of the benchmarks tackled by existing synthesizers, often starting from a more concise and intuitive user input.<br></td>
        </tr>

        <tr class="odd">
            <td>Informal</td>
            <td>12/8 4-5pm@3941 BBB</td>
            <td><a href="https://www.cs.cmu.edu/~crary/819-f09/Murthy91.pdf">An Evaluation Semantics for Classical Proofs</a></td>
        </tr>
        <tr class="even">
            <td></td>
            <td colspan="2"></td>
        </tr>

        </tbody>
    </table>


        </main>
    </body>
</html>

        </p>
    
</div>

        </main>

        <footer>
            <ul style="margin: 0; list-style: none">
                <li>
                    <a href="https://github.com/mplse-reading-group/mplse-reading-group.github.io">Site Source</a>
                </li>
                <li>
                    Site proudly generated by
                    <a href="http://jaspervdj.be/hakyll">Hakyll</a>
                </li>
            </ul>
        </footer>
    </body>
</html>
